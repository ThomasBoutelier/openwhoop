{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import struct\n",
    "import datetime\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from scipy.signal import medfilt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"\"\"\n",
    "select \n",
    "    lower(hex(bytes)) as packets_hex,\n",
    "    bytes as packet\n",
    "from packets \n",
    "where (lower(hex(bytes)) like \"aa6400a1%\" or lower(hex(bytes)) like \"aa5c00f0%\") and lower(hex(uuid)) = \"610800058d6d82b8614a1c8cb0f8dcc6\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_URL = os.getenv(\"DATABASE_URL\").replace(\"sqlite://\", \"sqlite:///../\")\n",
    "df = pd.read_sql(QUERY, DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"datetime\"] = pd.to_datetime(df[\"packet\"].apply(lambda data: struct.unpack('<I', data[11:15])[0]), unit=\"s\")\n",
    "df = df.sort_values(\"datetime\", ascending=True)\n",
    "\n",
    "df['date'] = df['datetime'].dt.date\n",
    "df['time'] = df['datetime'].dt.time\n",
    "df[\"bpm\"] = df[\"packet\"].apply(lambda data: data[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_rr(packet: bytes) -> list:\n",
    "    rr_count = packet[22]\n",
    "    packet = packet[23:]\n",
    "    \n",
    "    rr = []\n",
    "    for _ in range(4):\n",
    "        rr_value = struct.unpack('<H', packet[:2])[0]\n",
    "        packet = packet[2:]\n",
    "        if rr_value != 0:\n",
    "            rr.append(rr_value)\n",
    "\n",
    "    if len(rr) != rr_count:\n",
    "        raise ValueError(\"Invalid data\")\n",
    "    return rr\n",
    "\n",
    "df[\"rr\"] = df[\"packet\"].apply(parse_rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"stage\"] = df[\"packet\"].apply(lambda data: struct.unpack('<I', data[31:35])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heart_rate(days, column, plot_count = 2):\n",
    "    for index, day_data in enumerate(days):\n",
    "        # Create a figure with secondary y-axes\n",
    "        fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "        # Add heart rate trace to primary y-axis\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=day_data['datetime'], y=day_data['bpm'], mode='lines', name='Heart Rate (BPM)', line=dict(color='blue')),\n",
    "            secondary_y=False,\n",
    "        )\n",
    "\n",
    "        # Add x trace to secondary y-axis\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=day_data['datetime'], y=day_data[column], mode='lines', name='X', line=dict(color='orange')),\n",
    "            secondary_y=True,\n",
    "        )\n",
    "\n",
    "        # Update layout for titles and axes\n",
    "        fig.update_layout(\n",
    "            title=f\"Heart Rate and XYZ from {day_data['datetime'].iloc[0].date()} Noon to Next Day Noon\",\n",
    "            xaxis_title=\"Time\",\n",
    "            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
    "        )\n",
    "\n",
    "        # Update x-axis for time formatting\n",
    "        fig.update_xaxes(tickformat='%H:%M')\n",
    "\n",
    "        # Update y-axes titles\n",
    "        fig.update_yaxes(title_text=\"Heart Rate (BPM)\", secondary_y=False)\n",
    "        fig.update_yaxes(title_text=\"XYZ Values\", secondary_y=True)\n",
    "\n",
    "        # Show the plot\n",
    "        fig.show()\n",
    "\n",
    "        if index == plot_count:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_noon_to_noon(df):\n",
    "    # Group the data by date\n",
    "    days = []\n",
    "    unique_dates = df['date'].unique()\n",
    "    \n",
    "    for date in unique_dates:\n",
    "        # Define noon of the current day and noon of the next day\n",
    "        start_noon = pd.Timestamp(datetime.datetime.combine(date, datetime.time(12, 0)))\n",
    "        end_noon = start_noon + pd.Timedelta(days=1)\n",
    "        \n",
    "        # Filter data between the start and end noon\n",
    "        day_data = df[(df['datetime'] >= start_noon) & (df['datetime'] < end_noon)].copy()\n",
    "        if not day_data.empty:\n",
    "            days.append(day_data)\n",
    "\n",
    "    return days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spikes_row(row, window_size=3, threshold=3):\n",
    "    # Apply median filter\n",
    "    filtered = medfilt(row, kernel_size=window_size)\n",
    "    # Identify spikes\n",
    "    deviation = np.abs(row - filtered)\n",
    "    is_spike = deviation > threshold * np.std(row)\n",
    "    # Replace spikes with filtered values\n",
    "    smoothed = row.copy()\n",
    "    smoothed[is_spike] = filtered[is_spike]\n",
    "    return smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"stage\"] = remove_spikes_row(df[\"stage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"stage\"] < 500_000_000, \"stage_category\"] = 0\n",
    "df.loc[(df[\"stage\"] >= 500_000_000) & (df[\"stage\"] < 1000_000_000), \"stage_category\"] = 1\n",
    "df.loc[(df[\"stage\"] >= 1000_000_000) & (df[\"stage\"] < 1500_000_000), \"stage_category\"] = 2\n",
    "df.loc[df[\"stage\"] > 1500_000_000, \"stage_category\"] = 3\n",
    "df[\"stage_category\"] = df[\"stage_category\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = filter_noon_to_noon(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heart_rate(days, \"stage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heart_rate(days, \"stage_category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVITY_DURATION = 600 * 2\n",
    "\n",
    "def calculate_heart_rate_stats(row, bpm_df):\n",
    "    mask = (bpm_df['datetime'] >= row['start']) & (bpm_df['datetime'] <= row['end'])\n",
    "    relevant_bpm = bpm_df.loc[mask, 'bpm']\n",
    "    return pd.Series([\n",
    "        relevant_bpm.mean().round().astype(\"int64\"), \n",
    "        relevant_bpm.min().astype(\"int64\"), \n",
    "        relevant_bpm.max().astype(\"int64\")\n",
    "    ])\n",
    "\n",
    "def calculate_rmssd(window):\n",
    "    rr_diff = np.diff(window)\n",
    "    return np.sqrt(np.mean(rr_diff**2)) if len(rr_diff) > 0 else np.nan\n",
    "\n",
    "def calculate_avg_rmssd(row, df):\n",
    "    rr_data = df[(df['datetime'] >= row[\"start\"]) & (df['datetime'] <= row[\"end\"])][\"rr\"].explode().reset_index(drop=True).dropna()\n",
    "    hrv = rr_data.rolling(300).apply(calculate_rmssd, raw=True).dropna()\n",
    "    \n",
    "    return pd.Series([\n",
    "        hrv.mean().astype(\"int64\"),\n",
    "        hrv.min().astype(\"int64\"),\n",
    "        hrv.max().astype(\"int64\")\n",
    "    ])\n",
    "\n",
    "\n",
    "def detect_stages(df, stage):\n",
    "    change = df[\"stage_category\"] == df[\"stage_category\"].shift(1)\n",
    "    stage_3 = df[\"stage_category\"] == stage\n",
    "    sleep_starts = df[~change & stage_3][\"datetime\"].tolist()\n",
    "\n",
    "    change = df[\"stage_category\"] == df[\"stage_category\"].shift(-1)\n",
    "    stage_3 = df[\"stage_category\"] == stage\n",
    "    sleep_ends = df[~change & stage_3][\"datetime\"].tolist()\n",
    "    \n",
    "    stages = pd.DataFrame(list(zip(sleep_starts, sleep_ends)), columns=[\"start\", \"end\"])\n",
    "\n",
    "    while True:\n",
    "        stages[\"next_start\"] = stages[\"start\"].shift(-1)\n",
    "        stages[\"duration\"] = (stages[\"end\"] - stages[\"start\"]).apply(lambda x: x.total_seconds())\n",
    "        stages[\"sleep_diff\"] = (stages[\"next_start\"] - stages[\"end\"]).apply(lambda x: x.total_seconds())\n",
    "\n",
    "        merge_mask = stages[\"sleep_diff\"] < ACTIVITY_DURATION\n",
    "        \n",
    "        if not merge_mask.any():\n",
    "            break\n",
    "            \n",
    "        for idx in merge_mask[merge_mask].index:\n",
    "            if idx + 1 >= len(stages):\n",
    "                continue\n",
    "\n",
    "            stages.at[idx, \"end\"] = stages.at[idx + 1, \"end\"]\n",
    "            stages = stages.drop(idx + 1)\n",
    "        \n",
    "        stages = stages.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    stages[\"duration\"] = (stages[\"end\"] - stages[\"start\"]).apply(lambda x: x.total_seconds())\n",
    "    stages = stages[stages[\"duration\"] >= ACTIVITY_DURATION]\n",
    "\n",
    "    stages = stages[[\"start\", \"end\", \"duration\"]].reset_index(drop=True)\n",
    "    stages[\"duration\"] = (stages[\"end\"] - stages[\"start\"]).apply(lambda x: round(x.total_seconds() / 3600, 2))\n",
    "    stages[['avg_bpm', 'min_bpm', 'max_bpm']] = stages.apply(\n",
    "        calculate_heart_rate_stats, bpm_df=df, axis=1\n",
    "    )\n",
    "    stages[[\"avg_hrv\", \"min_hrv\", \"max_hrv\"]] = stages.apply(calculate_avg_rmssd, df=df, axis=1)\n",
    "    return stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df = detect_stages(df, 2)\n",
    "sleep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercises = detect_stages(df, 1)\n",
    "exercises"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
